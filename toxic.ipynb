{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/optimum","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/accelerate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nfrom optimum.bettertransformer import BetterTransformer\nfrom accelerate import Accelerator, notebook_launcher # main interface, distributed launcher\nfrom accelerate.utils import set_seed # reproducability across devices\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\ndir = None\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        dir = os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"read = [\"comment_id\", \"comment_text\"]\ndf_comments = pd.read_csv(dir, usecols=read)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport nltk\n# download the NLTK resources (run this line only once)\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define a function to tag POS in a sentence\ndef pos_tag(sentence):\n    tokens = nltk.word_tokenize(sentence)\n    tags = nltk.pos_tag(tokens)\n    return tags\n\n# apply the function to the 'text' column of the DataFrame\ndf_comments['pos_tags'] = df_comments['comment_text'].apply(pos_tag)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def is_question(tags):\n    # check if the sentence starts with an auxiliary verb\n    if len(tags) > 2 and tags[0][1].startswith('VB') and tags[1][1].startswith('PR'):\n        # check if the third tag is a main verb\n        return tags[2][1].startswith('VB')\n    else:\n        return False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"is_question_cond = ((df_comments.pos_tags.apply(lambda x: is_question(x))) | \n                    (df_comments.comment_text.str.startswith((\"What\", \"When\", \"Where\", \"Which\", \"Who\", \"Whom\", \"Whose\", \"Why\", \"How\", \"Could\", \"Should\", \"Would\", \"Can\"))) | \n                    (df_comments.comment_text.str.contains(\"?\", regex=False)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_comments[\"questions\"] = is_question_cond.astype(bool)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport transformers\n\nDOWNLOAD_URL = \"https://github.com/unitaryai/detoxify/releases/download/\"\nMODEL_URLS = {\n    \"original\": DOWNLOAD_URL + \"v0.1-alpha/toxic_original-c1212f89.ckpt\",\n    \"unbiased\": DOWNLOAD_URL + \"v0.3-alpha/toxic_debiased-c7548aa0.ckpt\",\n    \"multilingual\": DOWNLOAD_URL + \"v0.4-alpha/multilingual_debiased-0b549669.ckpt\",\n    \"original-small\": DOWNLOAD_URL + \"v0.1.2/original-albert-0e1d6498.ckpt\",\n    \"unbiased-small\": DOWNLOAD_URL + \"v0.1.2/unbiased-albert-c8519128.ckpt\",\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model_and_tokenizer(\n    model_type, model_name, tokenizer_name, num_classes, state_dict, huggingface_config_path=None\n):\n    model_class = getattr(transformers, model_name)\n    model = model_class.from_pretrained(\n        pretrained_model_name_or_path=None,\n        config=huggingface_config_path or model_type,\n        num_labels=num_classes,\n        state_dict=state_dict,\n        local_files_only=huggingface_config_path is not None,\n    )\n    tokenizer = getattr(transformers, tokenizer_name).from_pretrained(\n        huggingface_config_path or model_type,\n        local_files_only=huggingface_config_path is not None,\n        # TODO: may be needed to let it work with Kaggle competition\n        # model_max_length=512,\n    )\n\n    return model, tokenizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_checkpoint(model_type=\"original\", checkpoint=None, device=\"cpu\", huggingface_config_path=None):\n    if checkpoint is None:\n        checkpoint_path = MODEL_URLS[model_type]\n        loaded = torch.hub.load_state_dict_from_url(checkpoint_path, map_location=device)\n    else:\n        loaded = torch.load(checkpoint, map_location=device)\n        if \"config\" not in loaded or \"state_dict\" not in loaded:\n            raise ValueError(\n                \"Checkpoint needs to contain the config it was trained \\\n                    with as well as the state dict\"\n            )\n    class_names = loaded[\"config\"][\"dataset\"][\"args\"][\"classes\"]\n    # standardise class names between models\n    change_names = {\n        \"toxic\": \"toxicity\",\n        \"identity_hate\": \"identity_attack\",\n        \"severe_toxic\": \"severe_toxicity\",\n    }\n    class_names = [change_names.get(cl, cl) for cl in class_names]\n    model, tokenizer = get_model_and_tokenizer(\n        **loaded[\"config\"][\"arch\"][\"args\"],\n        state_dict=loaded[\"state_dict\"],\n        huggingface_config_path=huggingface_config_path,\n    )\n\n    return model, tokenizer, class_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, tokenizer, class_names = load_checkpoint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BetterTransformer.transform(model, keep_original_model=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n# Report the number of sentences.\nprint('Number of test sentences: {:,}\\n'.format(df_comments.shape[0]))\n\n# Create sentence and label lists\nsentences = df_comments.comment_text.values\n\n# Tokenize all of the sentences and map the tokens to thier word IDs.\ninput_ids = []\nattention_masks = []\n\n# For every sentence...\nfor sent in sentences:\n    # `encode_plus` will:\n    #   (1) Tokenize the sentence.\n    #   (2) Prepend the `[CLS]` token to the start.\n    #   (3) Append the `[SEP]` token to the end.\n    #   (4) Map tokens to their IDs.\n    #   (5) Pad or truncate the sentence to `max_length`\n    #   (6) Create attention masks for [PAD] tokens.\n    encoded_dict = tokenizer.encode_plus(\n                        sent,                      # Sentence to encode.\n                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n                        max_length = 512,           # Pad & truncate all sentences.\n                        pad_to_max_length = True,\n                        return_attention_mask = True,   # Construct attn. masks.\n                        return_tensors = 'pt',     # Return pytorch tensors.\n                   )\n    \n    # Add the encoded sentence to the list.    \n    input_ids.append(encoded_dict['input_ids'])\n    \n    # And its attention mask (simply differentiates padding from non-padding).\n    attention_masks.append(encoded_dict['attention_mask'])\n\n# Convert the lists into tensors.\ninput_ids = torch.cat(input_ids, dim=0)\nattention_masks = torch.cat(attention_masks, dim=0)\n\n# Set the batch size.  \nbatch_size = 32  \n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, SequentialSampler, DataLoader\nimport pickle\n# Create the DataLoader.\nprediction_data = TensorDataset(input_ids, attention_masks)\nprediction_sampler = SequentialSampler(prediction_data)\nprediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction on test set\ndef training_loop(model, dataloader, mixed_precision:str=\"fp16\", seed:int=42, batch_size:int=32):\n\n    \n    accelerator = Accelerator()\n    \n    model = accelerator.prepare(model)\n    \n    # Put model on accelerator device\n    model = model.to(accelerator.device)\n\n    # Wrap dataloader with accelerator.prepare()\n    dataloader = accelerator.prepare(dataloader)\n\n    # Put model in evaluation mode\n    model.eval()\n    \n    predictions=[]\n    \n    # Predict \n    for batch in dataloader:\n        # Unpack the inputs from our dataloader\n        b_input_ids, b_input_mask = batch\n\n        # Telling the model not to compute or store gradients, saving memory and \n        # speeding up prediction\n        with torch.no_grad():\n            # Forward pass, calculate logit predictions\n            outputs_toxic = model(b_input_ids, token_type_ids=None, \n            attention_mask=b_input_mask)\n\n        logits_toxic = outputs_toxic[0]\n\n        # Store predictions and true labels\n        predictions.append(torch.sigmoid(accelerator.gather(logits_toxic)).cpu().detach().numpy())\n        \n    pickle.dump(predictions, open(\"/kaggle/working/preds.pickle\", \"wb\"))\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nargs = (model, prediction_dataloader, \"fp16\", 42, 32)\nnotebook_launcher(training_loop, args, num_processes=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = pickle.load(open(\"/kaggle/working/preds.pickle\", \"rb\"))\nflat_predictions = np.concatenate(predictions, axis=0)\nname = \"negative\"\ndf_comments[class_names] = flat_predictions\n\ndf_comments = df_comments[~df_comments.comment_text.str.startswith(\"@\")].dropna()\ncond = (df_comments.toxicity > df_comments.toxicity.median()) & (df_comments.obscene < 0.15)  & (df_comments.insult > df_comments.insult.quantile(0.9)) & (df_comments.identity_attack > df_comments.identity_attack.quantile(0.99))\ndf_comments[\"negative\"] = cond\n\ndf_comments.drop(class_names, 1).reset_index().to_csv(\"preds.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}